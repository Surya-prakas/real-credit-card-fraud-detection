# -*- coding: utf-8 -*-
"""deep learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DDS08AtG5aaaL6w7s7VKeqvZPAQgxYtn
"""

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
from imblearn.over_sampling import SMOTE
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Set a random seed for reproducibility
np.random.seed(5)

data = pd.read_csv('/content/drive/MyDrive/creditcard.csv')
data['normalizedamt'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))
data = data.drop(['Amount', 'Time'], axis=1)

# prompt: count of classes in dataset

class_counts = data['Class'].value_counts()
class_counts

"""head.describe()"""

from google.colab import files
data.head(10).to_csv('data_snippet.csv', index=False)
files.download('data_snippet.csv')

from google.colab import drive
drive.mount('/content/drive')

data.info()

# Split into features and target
X = data.iloc[:, data.columns != 'Class']
y = data.iloc[:, data.columns == 'Class']

# Apply SMOTE for handling class imbalance
X_resample, y_resample = SMOTE().fit_resample(X, y.values.ravel())
X_resample = pd.DataFrame(X_resample)
y_resample = pd.DataFrame(y_resample)

X_train, X_test, y_train, y_test = train_test_split(X_resample, y_resample, test_size=0.25, stratify=y_resample, random_state=5)

# Convert data to NumPy arrays
X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)

# Build the deep learning model
model = Sequential([
    Dense(units=64, input_dim=X_train.shape[1], activation='relu'),  # Increased neurons for better learning
    Dropout(0.3),  # Adjusted dropout rate for optimal regularization
    Dense(units=32, activation='relu'),
    Dropout(0.3),
    Dense(units=16, activation='relu'),
    Dense(1, activation='sigmoid')  # Sigmoid for binary classification
])

# Compile the model with class weighting
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Configure callbacks for better training
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)

# Train the model with validation split
model.fit(
    X_train, y_train,
    batch_size=32,  # Adjusted for better gradient estimation
    epochs=50,  # Higher epochs with early stopping
    validation_split=0.2,
    class_weight={0: 1, 1: 3},  # Increase weight for minority class
    callbacks=[early_stopping, reduce_lr])

# Evaluate the model
score = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {score[1]:.4f}")

# Predict and calculate performance metrics
y_pred = model.predict(X_test)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred.round()))
print("\nClassification Report:")
print(classification_report(y_test, y_pred.round()))

import numpy as np

# Assuming new_samples is a numpy array with the same feature dimensions as X_train
new_samples = np.array([41, 1.138759336, -1.192952827, 1.407130836, -0.330070103, -2.06950346,
                        -0.242175406, -1.306635114, 0.104510403, 0.134628232, 0.493931277,
                        -0.895187598, -0.182695452, 0.146080827, -0.586610839, 0.797189022,
                        -0.891720829, -0.079207821, 1.541588494, -0.983586179, -0.299307434,
                        -0.156198372, -0.030568777, -0.019723384, 0.433752601, -0.02952146,
                        1.141241302, -0.00861206, 0.041563896, 96.94, 0])

# Select the first 29 elements to match the expected input shape (29 features)
new_samples = new_samples[:29]  # Adjust the slicing to select the correct number of features

# Reshape new_samples to be a 2D array with one row
new_samples = new_samples.reshape(1, -1)  # -1 infers the number of columns based on the original shape

# Use the model to predict
predictions = model.predict(new_samples)

# If you want to display the predictions
print(predictions)

# Print AUC-ROC score
roc_auc = roc_auc_score(y_test, y_pred)
print(f"AUC-ROC Score: {roc_auc:.4f}")

"""cross validation"""

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import precision_recall_curve, roc_curve, auc, confusion_matrix, classification_report, roc_auc_score
import matplotlib.pyplot as plt
import numpy as np

# Function for performing k-fold cross-validation
def cross_validate_model(model, X, y, folds=5):
    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)
    fold_no = 1
    aucs = []
    accuracy_scores = []

    for train_index, val_index in skf.split(X, y):
        # Split data into training and validation sets
        X_train_fold, X_val_fold = X[train_index], X[val_index]
        y_train_fold, y_val_fold = y[train_index], y[val_index]

        # Compile the model
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

        # Train the model
        model.fit(
            X_train_fold, y_train_fold,
            batch_size=32,
            epochs=50,
            validation_data=(X_val_fold, y_val_fold),
            class_weight={0: 1, 1: 3},  # Adjust based on imbalance
            callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
                       ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)],
            verbose=0  # Suppress detailed output for clarity
        )

        # Evaluate on validation data
        score = model.evaluate(X_val_fold, y_val_fold, verbose=0)
        y_pred_fold = model.predict(X_val_fold)

        # Calculate AUC
        roc_auc = roc_auc_score(y_val_fold, y_pred_fold)
        aucs.append(roc_auc)
        accuracy_scores.append(score[1])

        print(f"Fold {fold_no} - AUC: {roc_auc:.4f}, Accuracy: {score[1]:.4f}")
        fold_no += 1

    print("\nCross-Validation Results:")
    print(f"Mean AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}")
    print(f"Mean Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}")

# Convert the Pandas DataFrame to NumPy arrays (if not already done)
X_resample = np.array(X_resample)
y_resample = np.array(y_resample)

# Run k-fold cross-validation on the model
cross_validate_model(model, X_resample, y_resample)

# Plot Precision-Recall and ROC Curves for the final evaluation on a holdout set
y_pred_prob = model.predict(X_test)
precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

# Plot Precision-Recall curve
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(recall, precision, marker='.')
plt.title('Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')

# Plot ROC curve
plt.subplot(1, 2, 2)
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')

plt.tight_layout()
plt.show()

# Print confusion matrix and classification report
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_prob.round()))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_prob.round()))

# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, roc_curve, auc
import matplotlib.pyplot as plt
from sklearn.utils import shuffle

# Function to test the model on new or independent data
def evaluate_on_independent_data(model, X_test, y_test):
    # Evaluate the model on the test set
    y_pred_prob = model.predict(X_test)

    # Print confusion matrix and classification report
    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, y_pred_prob.round()))

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred_prob.round()))

    # Print AUC-ROC score
    roc_auc = roc_auc_score(y_test, y_pred_prob)
    print(f"AUC-ROC Score: {roc_auc:.4f}")

    # Plot Precision-Recall curve
    precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(recall, precision, marker='.')
    plt.title('Precision-Recall Curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')

    # Plot ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    plt.subplot(1, 2, 2)
    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.title('ROC Curve')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc='lower right')

    plt.tight_layout()
    plt.show()

# Use synthetic noise for stress testing
def stress_test_model(model, X_test, noise_factor=0.05):
    X_test_noisy = X_test + noise_factor * np.random.normal(size=X_test.shape)
    X_test_noisy = np.clip(X_test_noisy, X_test.min(), X_test.max())  # Ensure values stay in valid range

    print("\nEvaluating on Noisy Data:")
    evaluate_on_independent_data(model, X_test_noisy, y_test)

# Load an independent dataset (Assume this is a new dataset not used in training)
# Replace 'new_data.csv' with your new dataset path
new_data = pd.read_csv('/content/drive/MyDrive/creditcard.csv')
new_data['normalizedamt'] = StandardScaler().fit_transform(new_data['Amount'].values.reshape(-1, 1))
new_data = new_data.drop(['Amount', 'Time'], axis=1)

# Extract features and labels
X_new = new_data.drop('Class', axis=1).values
y_new = new_data['Class'].values

# Shuffle the data for randomness
X_new, y_new = shuffle(X_new, y_new, random_state=42)

# Evaluate the model on the new independent dataset
evaluate_on_independent_data(model, X_new, y_new)

# Perform stress testing with noisy data
stress_test_model(model, X_new)